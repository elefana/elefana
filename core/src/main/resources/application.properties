elefana.node.name=example
elefana.cluster.name=example-cluster

# HTTP bind address
elefana.http.address=127.0.0.1
elefana.http.port=9200

# Enable GZIP compression
elefana.http.gzip=true
# Maximum HTTP requests/responses per HTTP pipeline queue, 0 disables pipelining
elefana.http.maxEvents=0
# Maximum HTTP payload size (in bytes)
elefana.http.maxPayloadSize=104857600

# Elasticsearch API compatibility version
# 2 = Elasticsearch 2.x compatibility
# 5 = Elasticsearch 5.x compatibility
elefana.esCompatVersion=2

# True if citus extension is used in postgres
elefana.citus.enabled=false

# Citus coordinator node information
# Note: The host/port must be the same host/port that workers use to communicate with the coordinator node
elefana.citus.coordinator.host=127.0.0.1
elefana.citus.coordinator.port=5432
# Set to true to override auto-detection of local elefana node's direct connection to coordinator
#elefana.citus.coordinator.direct=false

# Citus worker node information
# Note: The host/port must be the same host/port that the coordinator node uses to communicate with the worker node
# These values should only be provided if this elefana node is connected to a worker node and not the coordinator
#elefana.citus.worker.host=127.0.0.1
#elefana.citus.worker.port=5432

# Bulk requests will be split across multiple PSQL connections
elefana.bulkParallelisation=4
# Frequency of when mappings should be refreshed (in milliseconds)
elefana.mappingInterval=1000
# Percentage of total rows to sample for mapping - increase/decrease based on total documents per index
elefana.mappingSampleSize=0.00001
# If bernoulli sampling returns 0 rows, fallback to the first N entries as a sample
elefana.fallbackMappingSampleSize=100
# Number of BRIN pages for BRIN index on timestamp ranges. Smaller values increase the accuracy of the index at cost of storage.
elefana.brinPagesPerRange=128
# Interval to clean up temporary tables (in milliseconds)
elefana.gcInterval=1000
# True if ingested JSON should be flattened (at cost of longer ingest time)
elefana.flattenJson=false
# True if ingested duplicate IDs should generate a new ID
elefana.regenerateDuplicateIds=false

# Metrics output target; noop, console or graphite
elefana.metrics.reporter=console
# Metrics reporting frequency (seconds)
elefana.metrics.frequency=5000
#elefana.metrics.graphite.prefix=your.host.name
#elefana.metrics.graphite.host=127.0.0.1
#elefana.metrics.graphite.port=9200

logging.path=D:\\Development\\logs

spring.datasource.url=jdbc:postgresql://localhost:5432/elefana?useUnicode=yes&amp;characterEncoding=UTF-8
spring.datasource.username=postgres
spring.datasource.password=postgres
spring.datasource.driver-class-name=org.postgresql.Driver
spring.datasource.hikari.connection-timeout=10000
spring.datasource.hikari.minimum-idle=5
spring.datasource.hikari.maximum-pool-size=10
spring.datasource.tomcat.test-while-idle=true
spring.datasource.tomcat.test-on-borrow=true
spring.datasource.tomcat.validation-query=SELECT NOW();
spring.datasource.tomcat.validation-interval=30000

# Bulk ingests data into one or more tablespaces. Note: tablespaces must already exist
#elefana.service.bulk.tablespaces=
# Determines no. of concurrently processed requests to bulk API
# Defaults to no. of cores when set to less than 1 or value is commented out
elefana.service.bulk.ingest.threads=4
# Determines no. of concurrently processed data for bulk indexing
# Defaults to no. of cores when set to less than 1 or value is commented out
elefana.service.bulk.index.threads=4
# Determines no. of concurrently processed requests to cluster info API
# Defaults to 2 when commented out
elefana.service.cluster.threads=2
# Determines no. of concurrently processed requests to document API
# Defaults to no. of cores when commented out
elefana.service.document.threads=4
# Store documents across one or more tablespaces. Note: tablespaces must already exist
#elefana.service.document.tablespaces=
# Determines no. of concurrently processed requests to field mapping/stats APIs
# Defaults to 2 when commented out
elefana.service.field.threads=4
# Determines no. of concurrently processed requests to node info API
# Defaults to 2 when commented out
elefana.service.node.threads=2
# Determines no. of concurrently processed count queries via search API
# Defaults to no. of cores when commented out
elefana.service.search.count.threads=4
# Determines no. of concurrently processed hits queries via search API
# Defaults to no. of cores when commented out
elefana.service.search.hits.threads=4
# Determines no. of concurrently processed aggregations via search API
# Defaults to no. of cores when commented out
elefana.service.search.aggregation.threads=4
# Determines no. of concurrently processed requests to template API
# Defaults to no. of cores when commented out
elefana.service.template.threads=4

# Determines how many seconds elapse until statistics about nodes are re-fetched
# Defaults to 1 second
# elefana.service.node.statsRefreshInterval=1

# Determines no. of concurrently analysed documents in fieldstats API
# Defaults to 2
# elefana.service.fieldStats.workerThreads=2

# Determines no. of concurrently processed requests to fieldstats API
# Defaults to 1
# elefana.service.fieldStats.requestThreads=1

# Determines the no. of minutes that need to elapse before a index is outdated in
# the fieldstats API.
# An outdated index is unloaded from memory and stored in the database
# Defaults to 10 minutes
# elefana.service.fieldStats.cache.ttlMinutes=10